{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random.TaskLocalRNG()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Gen, PyCall, Plots\n",
    "import Random, Logging\n",
    "\n",
    "Logging.disable_logging(Logging.Info);\n",
    "Random.seed!(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_dataset_line (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset\n",
    "function make_dataset_line(n)\n",
    "    # true parameters\n",
    "    prob_outlier = 0.2\n",
    "    true_inlier_noise = 0.5\n",
    "    true_outlier_noise = 5.0\n",
    "\n",
    "    true_slope = randn()*2\n",
    "    true_intercept = randn()*5\n",
    "    #print the true parameters\n",
    "    println(\"True slope: \", true_slope)\n",
    "    println(\"True intercept: \", true_intercept)\n",
    "\n",
    "    xs = collect(range(-5, stop=5, length=n))\n",
    "    ys = Float64[]\n",
    "    for (i, x) in enumerate(xs)\n",
    "        if randn() < prob_outlier\n",
    "            y = randn() * true_outlier_noise\n",
    "        else\n",
    "            y = true_slope * x + true_intercept + randn() * true_inlier_noise\n",
    "        end\n",
    "        push!(ys, y)\n",
    "    end\n",
    "    (xs, ys)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, adapted from playground to only use normal distributions\n",
    "@gen function regression_line(xs::Vector{<:Real})\n",
    "    # ...\n",
    "\n",
    "    slope ~ normal(0, 2)\n",
    "    intercept ~ normal(2, 2)\n",
    "\n",
    "    noise ~ normal(0.2, 0.03)\n",
    "    prob_outlier ~ normal(0, 1)\n",
    "\n",
    "    # Next, we generate the actual y coordinates.\n",
    "    n = length(xs)\n",
    "    ys = Float64[]\n",
    "\n",
    "    for i = 1:n\n",
    "        # Decide whether this point is an outlier, and set\n",
    "        # mean and standard deviation accordingly\n",
    "        outlier= {:data => (i, :is_outlier)} ~ normal(prob_outlier,0.5)\n",
    "\n",
    "        if outlier > 0\n",
    "            (mu, std) = (0., 10.)\n",
    "        else\n",
    "            (mu, std) = (xs[i] * slope + intercept, noise)\n",
    "        end\n",
    "        # Sample a y value for this point\n",
    "\n",
    "        y={:data => i => :y} ~ normal(mu, std)\n",
    "\n",
    "        push!(ys, y)\n",
    "\n",
    "    end\n",
    "    ys\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function testProposal_line(trace)\n",
    "\n",
    "    slope ~ normal(trace[:slope], 0.1)\n",
    "    intercept ~ normal(trace[:intercept], 0.1)\n",
    "    noise ~ normal(trace[:noise], 0.01)\n",
    "    prob_outlier ~ normal(trace[:prob_outlier], 0.01)\n",
    "\n",
    "    for i =1:10\n",
    "        outlier=@trace(normal(prob_outlier,0.5),(:data => i => :is_outlier))\n",
    "        if outlier > 0\n",
    "            (mu, std) = (0., 10.)\n",
    "        else\n",
    "            (mu, std) = (xs[i] * slope + intercept, noise)\n",
    "        end\n",
    "        # Sample a y value for this point\n",
    "        y=@trace(normal(mu, std), (:data,i,:y))\n",
    "    end\n",
    "    return nothing\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PyCall.PyError",
     "evalue": "PyError (PyImport_ImportModule\n\nThe Python package tensorflow could not be imported by pyimport. Usually this means\nthat you did not install tensorflow in the Python version being used by PyCall.\n\nPyCall is currently configured to use the Julia-specific Python distribution\ninstalled by the Conda.jl package.  To install the tensorflow module, you can\nuse `pyimport_conda(\"tensorflow\", PKG)`, where PKG is the Anaconda\npackage that contains the module tensorflow, or alternatively you can use the\nConda package directly (via `using Conda` followed by `Conda.add` etcetera).\n\nAlternatively, if you want to use a different Python distribution on your\nsystem, such as a system-wide Python (as opposed to the Julia-specific Python),\nyou can re-configure PyCall with that Python.   As explained in the PyCall\ndocumentation, set ENV[\"PYTHON\"] to the path/name of the python executable\nyou want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n\n) <class 'ModuleNotFoundError'>\nModuleNotFoundError(\"No module named 'tensorflow'\")\n",
     "output_type": "error",
     "traceback": [
      "PyError (PyImport_ImportModule\n",
      "\n",
      "The Python package tensorflow could not be imported by pyimport. Usually this means\n",
      "that you did not install tensorflow in the Python version being used by PyCall.\n",
      "\n",
      "PyCall is currently configured to use the Julia-specific Python distribution\n",
      "installed by the Conda.jl package.  To install the tensorflow module, you can\n",
      "use `pyimport_conda(\"tensorflow\", PKG)`, where PKG is the Anaconda\n",
      "package that contains the module tensorflow, or alternatively you can use the\n",
      "Conda package directly (via `using Conda` followed by `Conda.add` etcetera).\n",
      "\n",
      "Alternatively, if you want to use a different Python distribution on your\n",
      "system, such as a system-wide Python (as opposed to the Julia-specific Python),\n",
      "you can re-configure PyCall with that Python.   As explained in the PyCall\n",
      "documentation, set ENV[\"PYTHON\"] to the path/name of the python executable\n",
      "you want to use, run Pkg.build(\"PyCall\"), and re-launch Julia.\n",
      "\n",
      ") <class 'ModuleNotFoundError'>\n",
      "ModuleNotFoundError(\"No module named 'tensorflow'\")\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] pyimport(name::String)\n",
      "   @ PyCall ~/.julia/packages/PyCall/ilqDX/src/PyCall.jl:558\n",
      " [2] top-level scope\n",
      "   @ ~/dev/CS4340/compile_inference/reproduction.ipynb:14"
     ]
    }
   ],
   "source": [
    "#nn model line\n",
    "#inputs are:                                values\n",
    "# - x values                                10\n",
    "# - y values                                10\n",
    "# - address of sample (one hot encoded)     5\n",
    "# - instance id (one hot encoded)           10\n",
    "\n",
    "# - if lstm: previous hidden state\n",
    "\n",
    "#outputs are:\n",
    "# - mean\n",
    "# - std\n",
    "\n",
    "tf = pyimport(\"tensorflow\")\n",
    "keras = pyimport(\"keras\")\n",
    "\n",
    "def nn_line():\n",
    "    nn_model = keras.models.Sequential()\n",
    "    nn_model.add(keras.layers.Dense(10, input_shape=(35,), activation=\"relu\"))\n",
    "    nn_model.add(keras.layers.Dense(10, activation=\"relu\"))\n",
    "    nn_model.add(keras.layers.Dense(2, activation=\"linear\"))\n",
    "\n",
    "    #compile the model\n",
    "    nn_model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "    #train the model\n",
    "\n",
    "    #predict the mean and std\n",
    "    test=rand(1,35)\n",
    "    mean, std = nn_model.predict(test)\n",
    "    return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `make_dataset` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `make_dataset` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/dev/CS4340/compile_inference/reproduction.ipynb:3"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "xs, ys = make_dataset(10)\n",
    "\n",
    "constraints = choicemap()\n",
    "for (i, y) in enumerate(ys)\n",
    "    constraints[:data => i => :y] = y\n",
    "end\n",
    "\n",
    "(trace, _) = Gen.generate(regression, (xs,), constraints)\n",
    "\n",
    "# include a proposal\n",
    "for i=1:10\n",
    "    (trace, _) = Gen.mh(trace, testProposal, ())\n",
    "end\n",
    "\n",
    "println(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function coin_model()\n",
    "    val1 ~ normal(0, 1)\n",
    "    if val1 > 0\n",
    "        val2 ~ normal(0.5, 0.5)\n",
    "    else\n",
    "        val2 ~ normal(-0.5, 0.5)\n",
    "    end\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function coin_proposal(trace)\n",
    "    val1 ~ normal(trace[:val1], 0.1)\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "function block_resimulation_inference_coin(val2)\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:val2] = val2\n",
    "    (tr, ) = Gen.generate(coin_model, (), observations)\n",
    "    for iter=1:10000\n",
    "        (tr, ) = mh(tr, coin_proposal, ())\n",
    "        tr\n",
    "    end\n",
    "    tr\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value\n",
      "0.7883556016042917\n",
      "0.06007070202280035\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `block_resimulation_inference` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `block_resimulation_inference` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/dev/CS4340/compile_inference/reproduction.ipynb:8"
     ]
    }
   ],
   "source": [
    "trace = Gen.simulate(coin_model, ());\n",
    "choices=Gen.get_choices(trace)\n",
    "val2=choices[:val2]\n",
    "println(\"True value\")\n",
    "println(choices[:val1])\n",
    "println(choices[:val2])\n",
    "\n",
    "tr = block_resimulation_inference(val2)\n",
    "choices=Gen.get_choices(tr)\n",
    "\n",
    "println(\"Inferred value\")\n",
    "println(choices[:val1])\n",
    "println(choices[:val2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function burglar_model(chance)\n",
    "    burglar ~ bernoulli(chance)\n",
    "\n",
    "    if burglar\n",
    "        alarm ~ bernoulli(0.9)\n",
    "    else\n",
    "        alarm ~ bernoulli(0.15)\n",
    "    end\n",
    "\n",
    "    if alarm\n",
    "        john ~ bernoulli(0.6)\n",
    "        mary ~ bernoulli(0.7)\n",
    "    else\n",
    "        john ~ bernoulli(0.3)\n",
    "        mary ~ bernoulli(0.1)\n",
    "    end\n",
    "\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Any}:\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.916290731874155, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -2.071473372030659, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.6660082639224947, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.6660082639224947, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.6660082639224947, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -1.203972804325936, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -2.513306124309698, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.6660082639224947, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -2.3025850929940455, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -1.2039728043259361, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -4.362224007377701, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " ⋮\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -2.3025850929940455, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -1.2039728043259361, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -4.362224007377701, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.6660082639224947, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(true, -0.35667494393873245, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.916290731874155, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -2.071473372030659, 0.0, (0.5,), true)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(true, -0.10536051565782628, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -1.203972804325936, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -0.5108256237659907, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -2.513306124309698, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(false, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -0.16251892949777494, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(false, -0.35667494393873245, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -1.3177015696542789, 0.0, (0.5,), false)\n",
       " Gen.DynamicDSLTrace{DynamicDSLFunction{Any}}(DynamicDSLFunction{Any}(Dict{Symbol, Any}(), Dict{Symbol, Any}(), Type[Any], false, Union{Nothing, Some{Any}}[nothing], var\"##burglar_model#296\", Bool[0], false), Trie{Any, Gen.ChoiceOrCallRecord}(Dict{Any, Gen.ChoiceOrCallRecord}(:burglar => Gen.ChoiceOrCallRecord{Bool}(true, -0.6931471805599453, NaN, true), :alarm => Gen.ChoiceOrCallRecord{Bool}(false, -2.302585092994046, NaN, true), :mary => Gen.ChoiceOrCallRecord{Bool}(false, -0.10536051565782628, NaN, true), :john => Gen.ChoiceOrCallRecord{Bool}(true, -1.2039728043259361, NaN, true)), Dict{Any, Trie{Any, Gen.ChoiceOrCallRecord}}()), false, -4.305065593537753, 0.0, (0.5,), false)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "using PyCall\n",
    "\n",
    "# Import PyTorch\n",
    "nn = pyimport(\"torch.nn\")\n",
    "F = pyimport(\"torch.nn.functional\")\n",
    "# generate training data by sampling from the model:\n",
    "function generate_data(model, n, chance)\n",
    "    data = []\n",
    "    for i=1:n\n",
    "        (trace, _) = Gen.generate(model, (chance,), choicemap())\n",
    "        push!(data, trace)\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "data = generate_data(burglar_model, 100, .5)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject NeuralProposal(\n",
       "  (fc1): Linear(in_features=2, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
       "  (fc3): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "# Import PyTorch\n",
    "nn = pyimport(\"torch.nn\")\n",
    "F = pyimport(\"torch.nn.functional\")\n",
    "\n",
    "function y_from_trace(trace)\n",
    "    # return the value of y (mary, john) from the trace\n",
    "    choices = Gen.get_choices(trace)\n",
    "    return choices[:mary], choices[:john]\n",
    "end\n",
    "\n",
    "function x_from_trace(trace)\n",
    "    # return the value of x (burglar, alarm) from the trace\n",
    "    choices = Gen.get_choices(trace)\n",
    "    return choices[:burglar], choices[:alarm]\n",
    "end\n",
    "\n",
    "@pydef mutable struct NeuralProposal <: nn.Module\n",
    "    function __init__(self, num_in, num_out)\n",
    "        # Note the use of pybuiltin(:super): built in Python functions\n",
    "        # like `super` or `str` or `slice` are all accessed using\n",
    "        # `pybuiltin`.\n",
    "        pybuiltin(:super)(NeuralProposal, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_in, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, num_out)\n",
    "    end\n",
    "\n",
    "    function forward(self, x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # make sure the output is between 0 and 1\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "# input is tuple (john, mary)\n",
    "# output is parameters for (burglar, alarm)\n",
    "network = NeuralProposal(2, 2)\n",
    "network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicChoiceMap("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict{Any, Any}("
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":burglar => false, :alarm => false, :mary => false, :john => false), Dict{Any, Any}())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "│\n",
       "├── :burglar : false\n",
       "│\n",
       "├── :alarm : false\n",
       "│\n",
       "├── :mary : false\n",
       "│\n",
       "└── :john : false\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@gen function simple_neural_proposal(trace)\n",
    "    parameters = network(torch.tensor([trace[:john], trace[:mary]], dtype=torch.float32))\n",
    "    # extract float values from the PyTorch tensor\n",
    "    b_param = parameters[1].item()\n",
    "    a_param = parameters[2].item()\n",
    "\n",
    "    burglar ~ bernoulli(b_param)\n",
    "    alarm ~ bernoulli(a_param)\n",
    "end;\n",
    "\n",
    "\n",
    "function block_resimulation_burglar(john,mary, budget=1000, chance=0.5)\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:john] = john\n",
    "    observations[:mary] = mary\n",
    "    (tr, ) = Gen.generate(burglar_model, (chance,), observations)\n",
    "    for iter=1:budget\n",
    "        (tr, ) = mh(tr, select(:burglar, :alarm))\n",
    "    end\n",
    "    tr\n",
    "end;\n",
    "\n",
    "function nn_resimulation_burglar(john,mary, budget=1000, chance=0.5)\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:john] = john\n",
    "    observations[:mary] = mary\n",
    "    (tr, ) = Gen.generate(burglar_model, (chance,), observations)\n",
    "    for iter=1:budget\n",
    "        (tr, ) = mh(tr, simple_neural_proposal, ())\n",
    "    end\n",
    "    tr\n",
    "end;\n",
    "\n",
    "\n",
    "function make_constraints_burglar(trace)\n",
    "    choices = Gen.get_choices(trace)\n",
    "    constraints = choicemap()\n",
    "    constraints[:john] = choices[:john]\n",
    "    constraints[:mary] = choices[:mary]\n",
    "    constraints[:burglar] = choices[:burglar]\n",
    "    constraints[:alarm] = choices[:alarm]\n",
    "    return constraints\n",
    "end\n",
    "\n",
    "trace = Gen.simulate(burglar_model, (0.5,));\n",
    "\n",
    "println(\"True value\")\n",
    "c=make_constraints_burglar(trace)\n",
    "println(c)\n",
    "\n",
    "tr = block_resimulation_burglar(c[:john],c[:mary])\n",
    "choices=Gen.get_choices(tr)\n",
    "\n",
    "println(\"Inferred value\")\n",
    "c=make_constraints_burglar(tr)\n",
    "c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.621"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# how often does it get it right?\n",
    "function accuracy_burglar(model, data, inference, budget=1000, chance=0.5)\n",
    "    correct = 0\n",
    "    for trace in data\n",
    "        c = make_constraints_burglar(trace)\n",
    "        tr = inference(c[:john],c[:mary], budget, chance)\n",
    "        choices=Gen.get_choices(tr)\n",
    "        if choices[:burglar] == c[:burglar]\n",
    "            correct += 1\n",
    "        end\n",
    "    end\n",
    "    return correct / length(data)\n",
    "end\n",
    "\n",
    "chance = 0.5\n",
    "data = generate_data(burglar_model, 1000, chance)\n",
    "\n",
    "accuracy_burglar(burglar_model, data, block_resimulation_burglar, 100, chance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_burglar(burglar_model, data, nn_resimulation_burglar, 10, chance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: loss: 0.5626043429896236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: loss: 0.5435521984696389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: loss: 0.5432747783586382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: loss: 0.5427235867902637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: loss: 0.5430796567872167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: loss: 0.5428061211481691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: loss: 0.5426952903270721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: loss: 0.5425594559013843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: loss: 0.5423612278029323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: loss: 0.5424428292363882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11: loss: 0.5422440494596958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: loss: 0.5422611911222339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13: loss: 0.5421384634673595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14: loss: 0.5421387249454855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15: loss: 0.5419634680971503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: loss: 0.5419504527002573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17: loss: 0.5418596972599625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18: loss: 0.5417709210813045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19: loss: 0.5417040618881583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20: loss: 0.5415794762372971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21: loss: 0.5416261689588427\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:\n",
      "\n",
      "Stacktrace:\n",
      " [1] sigatomic_end\n",
      "   @ ./c.jl:452 [inlined]\n",
      " [2] disable_sigint\n",
      "   @ ./c.jl:475 [inlined]\n",
      " [3] __pycall!\n",
      "   @ ~/.julia/packages/PyCall/ilqDX/src/pyfncall.jl:42 [inlined]\n",
      " [4] _pycall!(ret::PyObject, o::PyObject, args::Tuple{}, nargs::Int64, kw::Ptr{Nothing})\n",
      "   @ PyCall ~/.julia/packages/PyCall/ilqDX/src/pyfncall.jl:29\n",
      " [5] _pycall!\n",
      "   @ ~/.julia/packages/PyCall/ilqDX/src/pyfncall.jl:11 [inlined]\n",
      " [6] #_#114\n",
      "   @ ~/.julia/packages/PyCall/ilqDX/src/pyfncall.jl:86 [inlined]\n",
      " [7] (::PyObject)()\n",
      "   @ PyCall ~/.julia/packages/PyCall/ilqDX/src/pyfncall.jl:86\n",
      " [8] top-level scope\n",
      "   @ ~/dev/CS4340/compile_inference/reproduction.ipynb:31"
     ]
    }
   ],
   "source": [
    "# now lets train the neural network\n",
    "\n",
    "# first, we need to convert the data into a format that PyTorch can use\n",
    "data = generate_data(burglar_model, 1000, chance)\n",
    "\n",
    "# the loss function is the negative log likelihood\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# the optimizer is the algorithm that updates the parameters\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# we will train for 100 epochs\n",
    "epochs = 100\n",
    "\n",
    "for epoch=1:epochs\n",
    "    losses = []\n",
    "    for trace in data\n",
    "        # convert the trace into a tensor\n",
    "        x = torch.tensor([trace[:john], trace[:mary]], dtype=torch.float32)\n",
    "        y = torch.tensor([trace[:burglar], trace[:alarm]], dtype=torch.float32)\n",
    "\n",
    "        # compute the output of the network\n",
    "        y_pred = network(x)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # add loss\n",
    "        push!(losses, loss.item())\n",
    "\n",
    "        # zero the gradients before running the backward pass.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "    end\n",
    "\n",
    "    mean_loss = sum(losses) / length(losses)\n",
    "    println(epoch, \": loss: \", mean_loss)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000-element Vector{Tuple{PyObject, PyObject}}:\n",
       " (PyObject tensor([0., 0.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 0.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([1., 0.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([0., 0.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 0.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([0., 1.]))\n",
       " ⋮\n",
       " (PyObject tensor([0., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([1., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([1., 0.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([0., 1.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([0., 0.]), PyObject tensor([0., 0.]))\n",
       " (PyObject tensor([0., 0.]), PyObject tensor([1., 0.]))\n",
       " (PyObject tensor([0., 1.]), PyObject tensor([1., 1.]))\n",
       " (PyObject tensor([0., 1.]), PyObject tensor([1., 1.]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using PyCall\n",
    "torch = pyimport(\"torch\")\n",
    "DataLoader = torch.utils.data.DataLoader\n",
    "\n",
    "# convert the data into a format that PyTorch can use\n",
    "data = generate_data(burglar_model, 100000, chance)\n",
    "\n",
    "# convert data to tensors and zip them\n",
    "data_tensors = [(torch.tensor([trace[:john], trace[:mary]], dtype=torch.float32),\n",
    "                 torch.tensor([trace[:burglar], trace[:alarm]], dtype=torch.float32)) for trace in data]\n",
    "data_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: loss: 0.5245602822303772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: loss: 0.5163607007265091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: loss: 0.5168133103847503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: loss: 0.5162248337268829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5: loss: 0.516531158387661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6: loss: 0.5169354456663132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: loss: 0.5165318793058395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: loss: 0.5165908205509185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: loss: 0.5169762372970581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: loss: 0.5167744207382202\n"
     ]
    }
   ],
   "source": [
    "network = NeuralProposal(2, 2)\n",
    "# create a DataLoader with batch size\n",
    "batch_size = 1000\n",
    "data_loader = DataLoader(data_tensors, batch_size=batch_size, shuffle=true)\n",
    "\n",
    "# the loss function is the negative log likelihood\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# the optimizer is the algorithm that updates the parameters\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "# we will train for 100 epochs\n",
    "epochs = 10\n",
    "\n",
    "for epoch=1:epochs\n",
    "    losses = []\n",
    "    for (x, y) in data_loader\n",
    "        # compute the output of the network\n",
    "        y_pred = network(x)\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        # add loss\n",
    "        push!(losses, loss.item())\n",
    "\n",
    "        # zero the gradients before running the backward pass.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # run the backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "    end\n",
    "\n",
    "    mean_loss = sum(losses) / length(losses)\n",
    "    println(epoch, \": loss: \", mean_loss)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <class 'LSTMProposal'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "# Import PyTorch\n",
    "nn = pyimport(\"torch.nn\")\n",
    "F = pyimport(\"torch.nn.functional\")\n",
    "\n",
    "@pydef mutable struct LSTMProposal <: nn.Module\n",
    "    function __init__(self; input_size::Int, hidden_size::Int, num_layers::Int, output_size::Int)\n",
    "        pybuiltin(:super)(LSTMProposal, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=true)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    end\n",
    "\n",
    "    function forward(self, x)\n",
    "        # Assuming x is of shape (batch, seq, feature)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        # We are taking the output of the last sequence step\n",
    "        last_seq_out = lstm_out[:, end, :]\n",
    "        out = self.linear(last_seq_out)\n",
    "        return out\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "syntax: newline not allowed after \":\" used for quoting",
     "output_type": "error",
     "traceback": [
      "syntax: newline not allowed after \":\" used for quoting\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/dev/CS4340/compile_inference/reproduction.ipynb:6"
     ]
    }
   ],
   "source": [
    "torch = pyimport(\"torch\")\n",
    "nn = torch.nn\n",
    "F = nn.functional\n",
    "\n",
    "function get_nn():\n",
    "    # inputs: observe = [john, mary], address (one hot), x_t-1\n",
    "    # outputs: mean, std\n",
    "    # LSTM\n",
    "    # input size: 2 (y: john, mary) + 2 (address: burglar or alarm) + 1 (x_t-1) = 5\n",
    "    input_size = 5\n",
    "    hidden_size = 10\n",
    "    num_layers = 1\n",
    "    output_size = 2\n",
    "    model = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "    return model\n",
    "end\n",
    "\n",
    "\n",
    "function train(model, inputs, outputs, epochs)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch=1:epochs\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs_pred = model(inputs)\n",
    "        loss = criterion(outputs_pred, outputs)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function burglar_proposal(trace)\n",
    "    burglar ~ bernoulli(0.6)\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "function block_resimulation_burglar(john,mary)\n",
    "    observations = Gen.choicemap()\n",
    "    observations[:john] = john\n",
    "    observations[:mary] = mary\n",
    "    (tr, ) = Gen.generate(burglar_model, (0.2,), observations)\n",
    "    for iter=1:10000\n",
    "        (tr, ) = mh(tr, burglar_proposal, ())\n",
    "        (tr, ) = mh(tr, select(:alarm))\n",
    "    end\n",
    "    tr\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True value\n",
      "DynamicChoiceMap(Dict{Any, Any}(:burglar => true, :alarm => true, :mary => true, :john => false), Dict{Any, Any}())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "│\n",
       "├── :burglar : false\n",
       "│\n",
       "├── :alarm : false\n",
       "│\n",
       "├── :mary : true\n",
       "│\n",
       "└── :john : false\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trace = Gen.simulate(burglar_model, (0.6,));\n",
    "\n",
    "println(\"True value\")\n",
    "c=make_constraints_burglar(trace)\n",
    "println(c)\n",
    "\n",
    "tr = block_resimulation_burglar(c[:john],c[:mary])\n",
    "choices=Gen.get_choices(tr)\n",
    "\n",
    "println(\"Inferred value\")\n",
    "c=make_constraints_burglar(tr)\n",
    "c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
